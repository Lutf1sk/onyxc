import "std/unix.nyx", "std/bitmath.nyx";

mcopy :: void(dst void*, src void*, bytes usz) {
	dst_it : u8* = dst;
	src_it : u8* = src;

	while bytes-- {
		*dst_it++ = *src_it++;
	}
};

mset8 :: void(dst void*, v u8, bytes usz) {
	it : u8* = dst;
	while bytes-- {
		*it++ = v;
	}
};

vmem_alloc :: void*(size usz) {
	addr := isz:mmap(0, size, PROT.READ|PROT.WRITE|PROT.EXEC, MAP.PRIVATE|MAP.ANONYMOUS, -1, 0);
	if (addr < 0) {
		return null;
	}
	return void*:addr;
};

vmem_free :: void(mem void*, size usz) {
	munmap(usz:mem, size);
};

VMEM_BLOCK_SIZE :: 4096;
ALLOC_DEFAULT_ALIGN :: 16;

ALLOC_FLAGS :: enum usz {
	FIXED_SIZE : 0x01, // Do not grow automatically when out of memory
	DONT_UNMAP : 0x02, // The memory should not be unmapped/deallocated after destruction
};

AllocFunc :: void*(alloc void*, size usz);
ReallocFunc :: void*(alloc void*, mem void*, new_size usz);
FreeFunc :: void(alloc void*, mem void*);
SizeFunc :: usz(alloc void*, mem void*);

Allocator :: struct {
	alloc	: AllocFunc;
	realloc	: ReallocFunc;
	free	: FreeFunc;
	size	: SizeFunc;
	usr		: void*;
};

malloc_init :: void[](alc Allocator*, arr void[]) {
	data := alc.alloc(alc.usr, arr.count);
	if !data {
		return null[0..0];
	}
	mcopy(data, arr.data, arr.count);
	return data[0..arr.count];
};

Pool :: struct {
	base		: void*;
	chunk_size	: usz;
	chunk_count	: usz;
	size		: usz;
	head		: void*;
	flags		: usz;
	parent		: Allocator*;
	interf		: Allocator;
};

_pmalloc_if :: void*(pool Pool*, size usz) {
	head : void** = pool.head;
	if !head || size > pool.chunk_size {
		return null;
	}
	pool.head = *head;
	return head;
};

_pmrealloc_if :: void*(pool Pool*, ptr void*, new_size usz) {
	if new_size > pool.chunk_size {
		return null;
	}
	return ptr;
};

_pmsize_if :: usz(pool Pool*, ptr void*) {
	return pool.chunk_size;
};

pmalloc :: void*(pool Pool*) {
	head : void** = pool.head;
	if !head {
		return null;
	}
	pool.head = *head;
	return head;
};

pmfree :: void(pool Pool*, ptr void*) {
	*void**:ptr = pool.head;
	pool.head = ptr;
};

pmreset :: void(pool Pool*) {
	last := &pool.head;
	it := pool.base;
	for i: ..pool.chunk_count {
		*last = it;
		last = it;
		it += pool.chunk_size;
	}
	*last = null;
};

pmcreatem :: Pool*(parent Allocator*, mem void*, size usz, chunk_size usz, flags usz) {
	headersz := alignf(sizeof(Pool), ALLOC_DEFAULT_ALIGN);

	if size < headersz || !chunk_size {
		return null;
	}

	if chunk_size < usz:sizeof(usz) {
		chunk_size = sizeof(usz);
	}

	pool : Pool* = mem;
	pool.base = mem + headersz;
	pool.chunk_size = chunk_size;
	pool.size = size;
	pool.chunk_count = (size - headersz) / chunk_size;
	pool.flags = flags;
	pool.parent = parent;
	pool.interf.alloc = AllocFunc: _pmalloc_if;
	pool.interf.realloc = ReallocFunc: _pmrealloc_if;
	pool.interf.free = FreeFunc: pmfree;
	pool.interf.size = SizeFunc: _pmsize_if;
	pool.interf.usr = pool;

	pmreset(pool);
	return pool;
};

pmcreate :: Pool*(parent Allocator*, size usz, chunk_size usz, flags usz) {
	base := null;
	if !parent {
		size = alignf(size, VMEM_BLOCK_SIZE);
		base = vmem_alloc(size);
	}
	else {
		size = alignf(size, ALLOC_DEFAULT_ALIGN);
		base = parent.alloc(parent.usr, size);
	}
	if !base {
		return null;
	}
	return pmcreatem(parent, base, size, chunk_size, flags);
};

pmdestroy :: void(pool Pool*) {
	if (pool.flags & ALLOC_FLAGS.DONT_UNMAP) { return; }

	if pool.parent {
		pool.parent.free(pool.parent.usr, pool);
	}
	else {
		vmem_free(pool.base, pool.size);
	}
};

Arena :: struct {
	base	: void*;
	size	: usz;
	top		: void*;
	flags	: usz;
	parent	: Allocator*;
	interf	: Allocator;
};

amalloc :: void*(arena Arena*, size usz) {
	start := void*:alignf(usz:arena.top, ALLOC_DEFAULT_ALIGN);
	new_top := start + ALLOC_DEFAULT_ALIGN + size;

	if new_top > arena.base + arena.size {
		return null;
	}
	*usz*:start = size;
	arena.top = new_top;
	return start + ALLOC_DEFAULT_ALIGN;
};

amrealloc :: void*(arena Arena*, ptr void*, new_size usz) {
	psize := usz*:(ptr - ALLOC_DEFAULT_ALIGN);

	if arena.top == ptr + *psize {
		if ptr + new_size > arena.base + arena.size {
			return null;
		}
		*psize = new_size;
		arena.top = ptr + new_size;
		return ptr;
	}

	new_ptr := amalloc(arena, new_size);
	if !new_ptr {
		return null;
	}
	mcopy(new_ptr, ptr, *psize);
	return new_ptr;
};

amfree :: void(arena Arena*, ptr void*) {
	old_size := *usz*:(ptr - ALLOC_DEFAULT_ALIGN);
	if arena.top == ptr + old_size {
		arena.top = ptr - ALLOC_DEFAULT_ALIGN;
	}
};

amsize :: usz(arena Arena*, ptr void*) {
	return *usz*:(ptr - ALLOC_DEFAULT_ALIGN);
};

amsave :: void*(arena Arena*) {
	return arena.top;
};

amrestore :: void(arena Arena*, old void*) {
	arena.top = old;
};

amcreatem :: Arena*(parent Allocator*, mem void*, size usz, flags usz) {
	if size < usz:sizeof(Arena) {
		return null;
	}

	arena : Arena* = mem;
	arena.base = mem;
	arena.size = size;
	arena.top = mem + sizeof(Arena); // Reserve enough memory to cover the header
	arena.flags = flags;
	arena.parent = parent;
	arena.interf.alloc = AllocFunc: amalloc;
	arena.interf.realloc = ReallocFunc: amrealloc;
	arena.interf.free = FreeFunc: amfree;
	arena.interf.size = SizeFunc: amsize;
	arena.interf.usr = arena;
	return arena;
};

amcreate :: Arena*(parent Allocator*, size usz, flags usz) {
	base : = null;
	if !parent {
		size = alignf(size, VMEM_BLOCK_SIZE);
		base = vmem_alloc(size);
	}
	else {
		size = alignf(size, ALLOC_DEFAULT_ALIGN);
		base = parent.alloc(parent.usr, size);
	}
	if !base {
		return null;
	}
	return amcreatem(parent, base, size, flags);
};

amdestroy :: void(arena Arena*) {
	if (arena.flags & ALLOC_FLAGS.DONT_UNMAP) { return; }

	if arena.parent {
		arena.parent.free(arena.parent.usr, arena);
	}
	else {
		vmem_free(arena.base, arena.size);
	}
};

